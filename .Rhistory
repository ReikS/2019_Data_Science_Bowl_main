workdir     <- paste0(date_dir, "/", par$run)
ifelse(!dir.exists(workdir), dir.create(workdir), FALSE)
setwd(workdir)
}
par <- list(run_mode        = "development", # possible values: "productive", "development"
on_machine      = "PC", # possible values: "PC", "notebook"
data_dir        = "E:/Wissensbasis/Projekte/kaggle/2019_Data_Science_Bowl/02_data",
input_dir       = "/input",
output_dir      = "/output",
submission_name = "submission.csv",
run             = "development_v0.1",
seed            = 123456,
start_date      = as.Date("2008-07-01"),
end_date        = as.Date("2018-09-30"),
hold_out        = 0.3,
k_folds         = 2,
t_times         = 1,
pre_processing  = c("zv"),
target_variable = "test_tar",
predictor = c("pred1", "pred2"))
#### only on PC set paths, create directories if they don't exists ####
if(par$on_machine == "PC"){
this_date   <- as.character(Sys.Date())
date_dir    <- paste0(par$data_dir, par$output_dir, "/", this_date)
ifelse(!dir.exists(date_dir), dir.create(date_dir), FALSE)
workdir     <- paste0(date_dir, "/", par$run)
ifelse(!dir.exists(workdir), dir.create(workdir), FALSE)
setwd(workdir)
}
ls()
#### only on PC set paths, create directories if they don't exists ####
if(par$on_machine == "PC"){
# output directory
this_date   <- as.character(Sys.Date())
date_dir    <- paste0(par$data_dir, par$output_dir, "/", this_date)
ifelse(!dir.exists(date_dir), dir.create(date_dir), FALSE)
workdir     <- paste0(date_dir, "/", par$run)
ifelse(!dir.exists(workdir), dir.create(workdir), FALSE)
setwd(workdir)
# directory for univariate analysis
univariate_dir <- paste0(workdir, "/", "univariate")
ifelse(!dir.exists(univariate_dir), dir.create(univariate_dir), FALSE)
}
################################ 2. Set Parameters and directories ################################
par <- list(run_mode        = "development", # possible values: "productive", "development"
on_machine      = "PC", # possible values: "PC", "notebook"
data_dir        = "E:/Wissensbasis/Projekte/kaggle/2019_Data_Science_Bowl/02_data",
input_dir       = "/input",
output_dir      = "/output",
submission_name = "submission.csv",
run             = "development_v0.1",
seed            = 123456,
start_date      = as.Date("2008-07-01"),
end_date        = as.Date("2018-09-30"),
hold_out        = 0.3,
k_folds         = 2,
t_times         = 1,
pre_processing  = c("zv"),
target_variable = "test_tar",
predictor = c("pred1", "pred2"))
#### only on PC set paths, create directories if they don't exists ####
if(par$on_machine == "PC"){
# output directory
this_date   <- as.character(Sys.Date())
date_dir    <- paste0(par$data_dir, par$output_dir, "/", this_date)
ifelse(!dir.exists(date_dir), dir.create(date_dir), FALSE)
workdir     <- paste0(date_dir, "/", par$run)
ifelse(!dir.exists(workdir), dir.create(workdir), FALSE)
setwd(workdir)
# directory for univariate analysis
univariate_dir <- paste0(workdir, "/", "univariate")
ifelse(!dir.exists(univariate_dir), dir.create(univariate_dir), FALSE)
}
#### parallel computing only possible on PC
if(par$on_machine == "PC"){
detectCores()
registerDoParallel(cores=detectCores() - 2)
}
# save parameter set that is used
capture.output(print(par), file = paste0(workdir, "/", "parameter_list_par.csv"))
################################ 2. Set Parameters and directories ################################
par <- list(run_mode        = "development", # possible values: "productive", "development"
on_machine      = "PC", # possible values: "PC", "notebook"
data_dir        = "E:/Wissensbasis/Projekte/kaggle/2019_Data_Science_Bowl/02_data",
input_dir       = "/input",
output_dir      = "/output",
submission_name = "submission.csv",
run             = "development_v0.1",
seed            = 123456,
start_date      = as.Date("2008-07-01"),
end_date        = as.Date("2018-09-30"),
hold_out        = 0.3,
k_folds         = 2,
t_times         = 1,
pre_processing  = c("zv"),
target_variable = "test_tar",
predictor = c("pred1", "pred2"))
# set input directory
par$in <- paste0(par$data_dir, par$input_dir)
#### only on PC set paths, create directories if they don't exists ####
if(par$on_machine == "PC"){
# output directory
this_date   <- as.character(Sys.Date())
date_dir    <- paste0(par$data_dir, par$output_dir, "/", this_date)
ifelse(!dir.exists(date_dir), dir.create(date_dir), FALSE)
workdir     <- paste0(date_dir, "/", par$run)
ifelse(!dir.exists(workdir), dir.create(workdir), FALSE)
setwd(workdir)
# set output directory to workdir
par$out <- workdir
# directory for univariate analysis
univariate_dir <- paste0(workdir, "/", "univariate")
ifelse(!dir.exists(univariate_dir), dir.create(univariate_dir), FALSE)
}
if(par$on_machine != "PC"){
# set output directory
par$out <- paste0(par$data_dir, par$output_dir)
}
#### parallel computing only possible on PC
if(par$on_machine == "PC"){
detectCores()
registerDoParallel(cores=detectCores() - 2)
}
# save parameter set that is used
capture.output(print(par), file = paste0(workdir, "/", "parameter_list_par.csv"))
ls()
par
################################ 2. Set Parameters and directories ################################
par <- list(run_mode        = "development", # possible values: "productive", "development"
on_machine      = "PC", # possible values: "PC", "notebook"
data_dir        = "E:/Wissensbasis/Projekte/kaggle/2019_Data_Science_Bowl/02_data",
input_dir       = "/input",
output_dir      = "/output",
submission_name = "submission.csv",
run             = "development_v0.1",
seed            = 123456,
start_date      = as.Date("2008-07-01"),
end_date        = as.Date("2018-09-30"),
hold_out        = 0.3,
k_folds         = 2,
t_times         = 1,
pre_processing  = c("zv"),
target_variable = "test_tar",
predictor = c("pred1", "pred2"))
# set input directory
par$inp <- paste0(par$data_dir, par$input_dir)
#### only on PC set paths, create directories if they don't exists ####
if(par$on_machine == "PC"){
# output directory
this_date   <- as.character(Sys.Date())
date_dir    <- paste0(par$data_dir, par$output_dir, "/", this_date)
ifelse(!dir.exists(date_dir), dir.create(date_dir), FALSE)
workdir     <- paste0(date_dir, "/", par$run)
ifelse(!dir.exists(workdir), dir.create(workdir), FALSE)
setwd(workdir)
# set output directory to workdir
par$out <- workdir
# directory for univariate analysis
univariate_dir <- paste0(workdir, "/", "univariate")
ifelse(!dir.exists(univariate_dir), dir.create(univariate_dir), FALSE)
}
if(par$on_machine != "PC"){
# set output directory
par$out <- paste0(par$data_dir, par$output_dir)
}
#### parallel computing only possible on PC
if(par$on_machine == "PC"){
detectCores()
registerDoParallel(cores=detectCores() - 2)
}
# save parameter set that is used
capture.output(print(par), file = paste0(workdir, "/", "parameter_list_par.csv"))
par
dat <- list(train = read.csv2(paste0(par$inp, "/", "train.csv")))
ls()
str(dat$train)
?read.csv
###################################################################################
# PROGRAM NAME :  2019_Data_Science_Bowl_main.R
#
# DESCRIPTION :   This R program serves as a prototype for the kaggle competition
#                 "2019_Data_Science_Bowl".
#
#                 The modeling process is based on the book
#                 "KuhnJohnson_Applied Predictive Modelling_2013"
#                 An online documentation of the caret package can also be found at
#                 http://topepo.github.io/caret/index.html
#                 A list of methods (packages) that can be used via caret can be found at
#                 https://rdrr.io/cran/caret/man/models.html
#
# CONTENT :       1. Initialisation of R session
#
#
# VERSION:        version 0.1
#
# CALLED BY :     none, is the main program
# CALLS TO :      none
#
# PROGRAMMER :    ReikS
# DATE WRITTEN :  2020-01-13
####################################################################################
# INPUT FILES :  "sample_submission.csv"
#                "specs.csv"
#                "test.csv"
#                "train.csv"
#                "train_labels.csv"
#
# OUTPUT FILES :
#
####################################################################################
# MODIFICATIONS 0.2 :
# ---------------------- : #
# DATE : yyyy-mm-dd
# CHANGE 1 :
# CHANGE 2 :
# PROGRAMMER : ReikS
# DESCRIPTION : #
####################################################################################
################################ 1. Initialisation of R session ################################
#### 1.a delete all objects from workspace
rm(list = ls())
memory.limit()
#### 1.b set options
options(scipen=999)
#### 1.c load packages
# define list of required packages
listOfPackages <- list("tidyverse", "coefplot", "caret", "caretEnsemble",
"glmnet", "randomForest", "ranger", "partykit",
"rpart", "rpart.plot", "randomForest", "bst",
"LiblineaR", "doParallel")
# load packages
lapply(listOfPackages,require,character.only = TRUE)
rm(listOfPackages)
################################ 2. Set Parameters and directories ################################
par <- list(run_mode        = "development", # possible values: "productive", "development"
on_machine      = "PC", # possible values: "PC", "notebook"
data_dir        = "E:/Wissensbasis/Projekte/kaggle/2019_Data_Science_Bowl/02_data",
input_dir       = "/input",
output_dir      = "/output",
submission_name = "submission.csv",
run             = "development_v0.1",
seed            = 123456,
start_date      = as.Date("2008-07-01"),
end_date        = as.Date("2018-09-30"),
hold_out        = 0.3,
k_folds         = 2,
t_times         = 1,
pre_processing  = c("zv"),
target_variable = "test_tar",
predictor = c("pred1", "pred2"))
# set input directory
par$inp <- paste0(par$data_dir, par$input_dir)
#### only on PC set paths, create directories if they don't exists ####
if(par$on_machine == "PC"){
# output directory
this_date   <- as.character(Sys.Date())
date_dir    <- paste0(par$data_dir, par$output_dir, "/", this_date)
ifelse(!dir.exists(date_dir), dir.create(date_dir), FALSE)
workdir     <- paste0(date_dir, "/", par$run)
ifelse(!dir.exists(workdir), dir.create(workdir), FALSE)
setwd(workdir)
# set output directory to workdir
par$out <- workdir
# directory for univariate analysis
univariate_dir <- paste0(workdir, "/", "univariate")
ifelse(!dir.exists(univariate_dir), dir.create(univariate_dir), FALSE)
}
if(par$on_machine != "PC"){
# set output directory
par$out <- paste0(par$data_dir, par$output_dir)
}
#### parallel computing only possible on PC
if(par$on_machine == "PC"){
detectCores()
registerDoParallel(cores=detectCores() - 2)
}
# save parameter set that is used
capture.output(print(par), file = paste0(workdir, "/", "parameter_list_par.csv"))
################ 3. load data from csv ################
dat <- list(test = read.csv(file = paste0(par$inp, "/", "train.csv"),
sep = ",", dec = ".", header = TRUE))
str(dat$test)
save.image("E:/Wissensbasis/Projekte/kaggle/2019_Data_Science_Bowl/02_data/output/2020-01-15/development_v0.1/ws1.RData")
################################ 1. Initialisation of R session ################################
#### 1.a delete all objects from workspace
rm(list = ls())
memory.limit()
#### 1.b set options
options(scipen=999)
#### 1.c load packages
# define list of required packages
listOfPackages <- list("tidyverse", "coefplot", "caret", "caretEnsemble",
"glmnet", "randomForest", "ranger", "partykit",
"rpart", "rpart.plot", "randomForest", "bst",
"LiblineaR", "doParallel")
# load packages
lapply(listOfPackages,require,character.only = TRUE)
rm(listOfPackages)
(.packages())
# "sample_submission.csv"
sample_submission <- read.csv(file = paste0(par$inp, "/", "sample_submission.csv"),
sep = ",", dec = ".", header = TRUE))
###################################################################################
# PROGRAM NAME :  2019_Data_Science_Bowl_main.R
#
# DESCRIPTION :   This R program serves as a prototype for the kaggle competition
#                 "2019_Data_Science_Bowl".
#
#                 The modeling process is based on the book
#                 "KuhnJohnson_Applied Predictive Modelling_2013"
#                 An online documentation of the caret package can also be found at
#                 http://topepo.github.io/caret/index.html
#                 A list of methods (packages) that can be used via caret can be found at
#                 https://rdrr.io/cran/caret/man/models.html
#
# CONTENT :       1. Initialisation of R session
#
#
# VERSION:        version 0.1
#
# CALLED BY :     none, is the main program
# CALLS TO :      none
#
# PROGRAMMER :    ReikS
# DATE WRITTEN :  2020-01-13
####################################################################################
# INPUT FILES :  "sample_submission.csv"
#                "specs.csv"
#                "test.csv"
#                "train.csv"
#                "train_labels.csv"
#
# OUTPUT FILES :
#
####################################################################################
# MODIFICATIONS 0.2 :
# ---------------------- : #
# DATE : yyyy-mm-dd
# CHANGE 1 :
# CHANGE 2 :
# PROGRAMMER : ReikS
# DESCRIPTION : #
####################################################################################
################################ 1. Initialisation of R session ################################
#### 1.a delete all objects from workspace
rm(list = ls())
memory.limit()
#### 1.b set options
options(scipen=999)
#### 1.c load packages
# define list of required packages
listOfPackages <- list("tidyverse", "coefplot", "caret", "caretEnsemble",
"glmnet", "randomForest", "ranger", "partykit",
"rpart", "rpart.plot", "randomForest", "bst",
"LiblineaR", "doParallel")
# load packages
lapply(listOfPackages,require,character.only = TRUE)
rm(listOfPackages)
################################ 2. Set Parameters and directories ################################
par <- list(run_mode        = "development", # possible values: "productive", "development"
on_machine      = "PC", # possible values: "PC", "notebook"
data_dir        = "E:/Wissensbasis/Projekte/kaggle/2019_Data_Science_Bowl/02_data",
input_dir       = "/input",
output_dir      = "/output",
submission_name = "submission.csv",
run             = "development_v0.1",
seed            = 123456,
start_date      = as.Date("2008-07-01"),
end_date        = as.Date("2018-09-30"),
hold_out        = 0.3,
k_folds         = 2,
t_times         = 1,
pre_processing  = c("zv"),
target_variable = "test_tar",
predictor = c("pred1", "pred2"))
# set input directory
par$inp <- paste0(par$data_dir, par$input_dir)
#### only on PC set paths, create directories if they don't exists ####
if(par$on_machine == "PC"){
# output directory
this_date   <- as.character(Sys.Date())
date_dir    <- paste0(par$data_dir, par$output_dir, "/", this_date)
ifelse(!dir.exists(date_dir), dir.create(date_dir), FALSE)
workdir     <- paste0(date_dir, "/", par$run)
ifelse(!dir.exists(workdir), dir.create(workdir), FALSE)
setwd(workdir)
# set output directory to workdir
par$out <- workdir
# directory for univariate analysis
univariate_dir <- paste0(workdir, "/", "univariate")
ifelse(!dir.exists(univariate_dir), dir.create(univariate_dir), FALSE)
}
if(par$on_machine != "PC"){
# set output directory
par$out <- paste0(par$data_dir, par$output_dir)
}
#### parallel computing only possible on PC
if(par$on_machine == "PC"){
detectCores()
registerDoParallel(cores=detectCores() - 2)
}
# save parameter set that is used
capture.output(print(par), file = paste0(workdir, "/", "parameter_list_par.csv"))
################ 3. load data from csv ################
# "sample_submission.csv"
sample_submission <- read.csv(file = paste0(par$inp, "/", "sample_submission.csv"),
sep = ",", dec = ".", header = TRUE))
# "sample_submission.csv"
sample_submission <- read.csv(file = paste0(par$inp, "/", "sample_submission.csv"),
sep = ",", dec = ".", header = TRUE)
str(sample_submission)
#### 3.a "sample_submission.csv"
sample_submission <- read.csv(file = paste0(par$inp, "/", "sample_submission.csv"), stringsAsFactors = FALSE,
sep = ",", dec = ".", header = TRUE)
str(sample_submission)
str(sample_submission)
head(sample_submission)
length(unique(sample_submission$installation_id)) == nrow(sample_submission)
################################ 2. Set Parameters and directories ################################
par <- list(run_mode        = "development", # possible values: "productive", "development"
on_machine      = "PC", # possible values: "PC", "notebook"
data_dir        = "E:/Wissensbasis/Projekte/kaggle/2019_Data_Science_Bowl/02_data",
input_dir       = "/input",
output_dir      = "/output",
submission_name = "submission.csv",
run             = "development_v0.1",
train_row       = 303319,
test_row        = 28445,
seed            = 123456,
start_date      = as.Date("2008-07-01"),
end_date        = as.Date("2018-09-30"),
hold_out        = 0.3,
k_folds         = 2,
t_times         = 1,
pre_processing  = c("zv"),
target_variable = "test_tar",
predictor = c("pred1", "pred2"))
# set input directory
par$inp <- paste0(par$data_dir, par$input_dir)
#### only on PC set paths, create directories if they don't exists ####
if(par$on_machine == "PC"){
# output directory
this_date   <- as.character(Sys.Date())
date_dir    <- paste0(par$data_dir, par$output_dir, "/", this_date)
ifelse(!dir.exists(date_dir), dir.create(date_dir), FALSE)
workdir     <- paste0(date_dir, "/", par$run)
ifelse(!dir.exists(workdir), dir.create(workdir), FALSE)
setwd(workdir)
# set output directory to workdir
par$out <- workdir
# directory for univariate analysis
univariate_dir <- paste0(workdir, "/", "univariate")
ifelse(!dir.exists(univariate_dir), dir.create(univariate_dir), FALSE)
}
if(par$on_machine != "PC"){
# set output directory
par$out <- paste0(par$data_dir, par$output_dir)
}
#### parallel computing only possible on PC
if(par$on_machine == "PC"){
detectCores()
registerDoParallel(cores=detectCores() - 2)
}
# save parameter set that is used
capture.output(print(par), file = paste0(workdir, "/", "parameter_list_par.csv"))
################ 3. load data from csv ################
#### 3.a "sample_submission.csv"
sample_submission <- read.csv(file = paste0(par$inp, "/", "sample_submission.csv"), stringsAsFactors = FALSE,
sep = ",", dec = ".", header = TRUE)
str(sample_submission)
head(sample_submission)
length(unique(sample_submission$installation_id)) == nrow(sample_submission)
#### 3.b "train.csv"
load_train_or_test <- function(par = par, dataset = "test", mode = "development"){
nrows <- ifelse(dataset = "test", par$test_row, par$train_row)
get_rows <- round(ifelse(mode == "development", 0.01, 1.0) * nrows)
return(get_rows)
}
load_train_or_test(par = par, dataset = "test", mode = "development")
#### 3.b "train.csv"
load_train_or_test <- function(par = par, dataset = "test", mode = "development"){
nrows <- ifelse(dataset == "test", par$test_row, par$train_row)
get_rows <- round(ifelse(mode == "development", 0.01, 1.0) * nrows)
return(get_rows)
}
load_train_or_test(par = par, dataset = "test", mode = "development")
#### 3.b "train.csv"
load_train_or_test <- function(par = par, dataset = "test", mode = "development"){
nrows <- ifelse(dataset == "test", par$test_row, par$train_row)
get_rows <- round(ifelse(mode == "development", 0.05, 1.0) * nrows)
return(get_rows)
}
load_train_or_test(par = par, dataset = "test", mode = "development")
#### 3.b "train.csv"
load_train_or_test <- function(par = par, dataset = "test", mode = "development"){
nrows <- ifelse(dataset == "test", par$test_row, par$train_row)
get_rows <- round(ifelse(mode == "development", 0.05, 1.0) * nrows)
#  return(read.csv(file = paste0(par$inp, "/", dataset, ".csv"), stringsAsFactors = FALSE,
#                  sep = ",", dec = ".", header = TRUE))
return(paste0(par$inp, "/", dataset, ".csv"))
}
load_train_or_test(par = par, dataset = "test", mode = "development")
#### 3.b "train.csv"
load_train_or_test <- function(par = par, dataset = "test", mode = "development"){
nrows <- ifelse(dataset == "test", par$test_row, par$train_row)
get_rows <- round(ifelse(mode == "development", 0.05, 1.0) * nrows)
return(read.csv(file = paste0(par$inp, "/", dataset, ".csv"), stringsAsFactors = FALSE,
sep = ",", dec = ".", header = TRUE))
}
load_train_or_test(par = par, dataset = "test", mode = "development")
test <- load_train_or_test(par = par, dataset = "test", mode = "development")
str(test)
